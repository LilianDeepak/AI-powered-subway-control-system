## 📜 Project Description
AI-powered subway control system designed to assist hand-disabled individuals by enabling touch-free interaction. Using advanced computer vision and AI, it detects hand gestures to operate subway controls safely and efficiently, promoting accessibility and independence in public transit.
# 🎮 AI-Powered Gesture-Based Subway Surfer Controller for Hand-Disabled Players

---



This project is a **gesture-based AI controller** built using **OpenCV**, **MediaPipe**, and **PyAutoGUI** that allows **individuals with hand disabilities** to play **Subway Surfer** (or similar online games) using only **head movements** detected through a webcam.

The controller **splits the camera frame into four zones**:
- Move head **right** ➡️ Triggers **Right Arrow** key
- Move head **left** ⬅️ Triggers **Left Arrow** key
- Move head **up** ⬆️ Triggers **Up Arrow** key (Jump)
- Move head **down** ⬇️ Triggers **Down Arrow** key (Slide)

This system provides a **hands-free, inclusive gaming experience** without any external hardware — just a normal webcam!

---

## ✨ Features

- 🎥 Real-time head tracking using MediaPipe.
- 🖥️ Screen split into four virtual control zones.
- 🕹️ Automated keyboard keypress simulation.
- ⚡ Lightweight and fast performance.
- ♿ Specially designed for hand-disabled individuals.
- 🚀 Easy to set up and run.

---

## 📦 Technologies Used

- Python 3.x
- OpenCV (cv2)
- MediaPipe
- PyAutoGUI

---



